spring:
  application:
    name: analytics-pusher
  profiles:
    active: dev
  datasource:
    mysql:
      url: jdbc:mysql://127.0.0.1:3306/analytics?userUnicode=true&&characterEncoding=utf8&allowMultiQueries=true&useSSL=false&allowPublicKeyRetrieval=true
      username: root
      password: root
      driver-class-name: com.mysql.cj.jdbc.Driver
      # 数据源类别
      type: com.alibaba.druid.pool.DruidDataSource
      # 数据源其他配置
      # 初始化数量
      initialSize: 20
      minIdle: 20
      maxActive: 150
      # 最大连接等待超时时间
      maxWait: 6000
      timeBetweenEvictionRunsMillis: 60000
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 1 FROM DUAL
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20
      filters: stat
      useGlobalDataSourceStat: true
  #    starrocks:
  #      url: jdbc:mysql://idata-starrocks-fe01-p.seeke.net:9030/product?userUnicode=true&&characterEncoding=utf8&allowMultiQueries=true&useSSL=false&autoReconnect=true&failOverReadOnly=false
  #      username: root
  #      password: root
  #      driver-class-name: com.cj.mysql.jdbc.Driver
  #      type: com.alibaba.druid.pool.DruidDataSource
  #      # 数据源其他配置
  #      # 初始化数量
  #      initialSize: 10
  #      minIdle: 10
  #      maxActive: 30
  #      # 最大连接等待超时时间
  #      maxWait: 150000
  #      timeBetweenEvictionRunsMillis: 60000
  #      minEvictableIdleTimeMillis: 150000
  #      validationQuery: SELECT "1"
  #      testWhileIdle: true
  #      testOnBorrow: false
  #      testOnReturn: false
  #      poolPreparedStatements: true
  #      maxPoolPreparedStatementPerConnectionSize: 20
  #      filters: stat
  #      useGlobalDataSourceStat: true
  #      filter:
  #        stat:
  #          merge-sql: false
  #    greenplum:
  #      url: jdbc:postgresql://hadoop-lable-greenplum-master-inc-t.seeke.net/idata
  #      username: gpadmin
  #      password: sigo@123
  #      type: com.alibaba.druid.pool.DruidDataSource
  #      driver-class-name: org.postgresql.Driver
  #      # 数据源其他配置
  #      maxActive: 200
  #      initialSize: 1
  #      maxWait: 30000
  #      minIdle: 1
  #      timeBetweenEvictionRunsMillis: 60000
  #      minEvictableIdleTimeMillis: 300000
  #      validationQuery: select 'x'
  #      testWhileIdle: true
  #      testOnBorrow: false
  #      testOnReturn: false
  #      poolPreparedStatements: true
  #      maxOpenPreparedStatements: 20
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.117.73:8848
        namespace: analytics_dev_namespace
      config:
        server-addr: 192.168.117.73:8848
        namespace: analytics_dev_namespace
        file-extension: yaml  # 文件后缀名
  kafka:
    bootstrap-servers: 52.82.98.209:10903,52.82.98.209:10904
    producer: # producer 生产者
      retries: 0 # 重试次数
      acks: 1 # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      batch-size: 16384 # 批量大小
      buffer-memory: 33554432 # 生产端缓冲区大小
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      #      value-serializer: com.itheima.demo.config.MySerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer: # consumer消费者
      group-id: javagroup # 默认的消费组ID
      enable-auto-commit: true # 是否自动提交offset
      auto-commit-interval: 100  # 提交offset延时(接收到消息后多久提交offset)
      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #      value-deserializer: com.itheima.demo.config.MyDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer


